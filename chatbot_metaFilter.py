# chatbot_fixed_v6_reranked.py (ì œëª© í•„í„°ë¥¼ Pythonì—ì„œ í›„ì²˜ë¦¬ + K í™•ëŒ€/Rerank)
import re
from typing import Dict, Any, List, Optional, Union
from commonUtil.timeCheck import logging_time
from datetime import datetime, timezone
import time  # time ëª¨ë“ˆì€ datetime ê°ì²´ë¥¼ íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
from dateutil.relativedelta import relativedelta
from pathlib import Path
# Reranker í•¨ìˆ˜ ì„í¬íŠ¸
from reranker import rerank_documents

# ---------- ì „ì—­ ì„¤ì • (í† í° ê¸°ë°˜ ë¶„í•  ê¸°ì¤€) ----------
DB_FOLDER = "./chroma_db3"  # -- ê¸°ë³¸ì€ ./chroma_db2
# V_Kwargs = 10 # -- ê¸°ì¡´ ì„¤ì • ëŒ€ì‹  K í™•ì¥ ì„¤ì • ì‚¬ìš©
# V_MODEL_NAME = "llama3.2:3b"
V_MODEL_NAME = "llama3.1:8b"

# ----------------------------------------------------

# ---------- âœ… Reranking ê´€ë ¨ ì „ì—­ ì„¤ì • ì¶”ê°€ ----------
USE_RERANKER = True  # ì¬ìˆœìœ„í™” ì‚¬ìš© ì—¬ë¶€ (True/False)
INITIAL_K = 20  # ì´ˆê¸° ChromaDB ê²€ìƒ‰ K ê°’
FINAL_K = 10  # ì¬ìˆœìœ„í™” í›„ ìµœì¢… ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜
# ----------------------------------------------------


# --- Imports: try newest, fallback to older packages if necessary ---
try:
    from langchain_chroma import Chroma
except Exception:
    from langchain_community.vectorstores import Chroma  # older langchain versions

try:
    from langchain_ollama import OllamaLLM
except Exception:
    from langchain_community.llms import Ollama as OllamaLLM  # fallback (older)

# Embeddings import fallback handling
try:
    from langchain_huggingface import HuggingFaceEmbeddings
except Exception:
    try:
        from langchain_community.embeddings import HuggingFaceEmbeddings
    except Exception:
        raise ImportError("HuggingFaceEmbeddings import failed. Install langchain_huggingface or langchain-community.")

from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.schema import Document

# ---------- PROMPT (ìƒëµ) ----------
PROMPT_TEMPLATE = """ë‹¹ì‹ ì€ íšŒì‚¬ ê²Œì‹œíŒì˜ ë¬¸ì„œë“¤ì„ ë¶„ì„í•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ì‹¤ì œ ë‚´ìš©ì…ë‹ˆë‹¤:
{context}

[ì§€ì‹œì‚¬í•­]
1. ë°˜ë“œì‹œ ë¬¸ì„œ ë‚´ìš©ì—ë§Œ ê·¼ê±°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
2. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , "ê´€ë ¨ ë¬¸ì„œì—ì„œ í•´ë‹¹ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”.
3. ì—¬ëŸ¬ ë¬¸ì„œê°€ ê²€ìƒ‰ëœ ê²½ìš°, metadataì˜ 'date' ê°’ì´ ê°€ì¥ ìµœì‹ ì¸ ë¬¸ì„œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
4. ë‚ ì§œê°€ ë™ì¼í•œ ê²½ìš° metadataì˜ 'ê²Œì‹œì¼ì‹œ'ë¥¼ ë¹„êµí•´ ìµœì‹  ê²Œì‹œê¸€ì„ ì„ íƒí•˜ì„¸ìš”.
5. ê°€ëŠ¥í•œ ê²½ìš° ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”: ì œëª©, ê²Œì‹œì, ê²Œì‹œì¼ì.

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}
"""


# ---------- ë²¡í„° DB ë¡œë“œ ----------
def load_vector_db(persist_dir: str = DB_FOLDER):
    embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")
    db = Chroma(persist_directory=persist_dir, embedding_function=embeddings)
    return db


# ---------- LLM ë¡œë“œ (ìƒëµ) ----------
def load_llm(gpu_acceleration: bool = False):
    """
    LLMì„ ë¡œë“œí•©ë‹ˆë‹¤. GPU ê°€ì† ì˜µì…˜ì— ë”°ë¼ ìµœì ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    model_name = V_MODEL_NAME

    config_params = {
        "temperature": 0.0,
        "model": model_name
    }

    if gpu_acceleration:
        # ğŸ’¡ GPU ì‚¬ìš© ì‹œ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ íŒŒë¼ë¯¸í„° ì¶”ê°€
        config_params.update({
            "num_gpu": 1,
            "mirostat": 2  # Mirostat ìƒ˜í”Œë§ v2 ì ìš©
        })
        print(f"ğŸš€ GPU ê°€ì† ì˜µì…˜ í™œì„±í™”: {model_name}")
    else:
        # CPU ì‚¬ìš© ì‹œ: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë° ì¶”ë¡  ì†ë„ë¥¼ ê³ ë ¤í•œ ê¸°ë³¸ ì„¤ì • ìœ ì§€
        print(f"ğŸ’» CPU ëª¨ë“œ í™œì„±í™”: {model_name}")

    try:
        return OllamaLLM(**config_params)
    except TypeError:
        # ë˜í¼ ë²„ì „ ì°¨ì´ë¡œ ì¸í•œ í‚¤ì›Œë“œ ì—ëŸ¬ ë°©ì§€ (fallback)
        return OllamaLLM(model=model_name, temperature=0.0)


# ---------- QA ì²´ì¸ ìƒì„± (Retriever k ê°’ ìˆ˜ì •) ----------
def create_qa_chain(gpu_acceleration: bool = False):
    db = load_vector_db()

    # Note: RetrievalQA ì²´ì¸ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³ , get_answerì—ì„œ raw ê²€ìƒ‰ì„ í•  ê²ƒì´ë¯€ë¡œ
    # ì´ í•¨ìˆ˜ì˜ retrieverëŠ” ê¸°ë³¸ Kë¥¼ ê°€ì§€ë„ë¡ ìœ ì§€í•˜ê±°ë‚˜, ë‹¨ìˆœ ë°˜í™˜ë§Œ í•©ë‹ˆë‹¤.
    # get_answerì—ì„œ raw APIë¥¼ ì‚¬ìš©í•´ K=INITIAL_Kë¥¼ ëª…ì‹œí•  ê²ƒì…ë‹ˆë‹¤.
    retriever = db.as_retriever(search_kwargs={"k": INITIAL_K})  # Kê°’ ì „ì—­ ë³€ìˆ˜ ë°˜ì˜
    llm = load_llm(gpu_acceleration=gpu_acceleration)

    # PromptTemplateì€ ë™ì¼í•˜ê²Œ ì‚¬ìš©
    map_prompt = PromptTemplate(input_variables=["context", "question"], template=PROMPT_TEMPLATE)

    # RetrievalQA ì²´ì¸ ìƒì„± ë¡œì§ì€ ìœ ì§€ (ì‚¬ìš©í•˜ì§€ ì•Šë”ë¼ë„ êµ¬ì¡° ìœ ì§€)
    qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type="stuff")

    return qa, db, retriever


# ---------- ì§ˆë¬¸ì—ì„œ í•„í„° ì¡°ê±´ ì¶”ì¶œ (ìƒëµ - ê¸°ì¡´ê³¼ ë™ì¼) ----------
def extract_chroma_filter(query: str) -> tuple[Union[Dict[str, Any], None], Union[str, None]]:
    # ... (ê¸°ì¡´ extract_chroma_filter í•¨ìˆ˜ ë‚´ìš© ê·¸ëŒ€ë¡œ ì‚¬ìš©) ...
    """
    ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ChromaDB ê²€ìƒ‰ì„ ìœ„í•œ í•„í„°ë§ ì¸ìì™€ ì œëª© í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    (ê¸°ì¡´ extract_chroma_filter í•¨ìˆ˜ ë‚´ìš© ê·¸ëŒ€ë¡œ í¬í•¨)
    """

    # ğŸ’¡ dateutil.relativedelta ì‚¬ìš©ì„ ìœ„í•´ ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install python-dateutil
    # í˜„ì¬ ì‹œì  (UTC ê¸°ì¤€)
    now_utc = datetime.now(timezone.utc)

    # 1. í•„í„° ì¡°ê±´ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    where_conditions: List[Dict[str, Any]] = []
    search_kwargs: Dict[str, Any] = {}
    title_keyword = None

    # --- A. ì œëª© í•„í„°ë§ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼) ---
    title_pattern = re.search(r"(ì œëª©|íƒ€ì´í‹€)[^\s]*\s*(?:(?:ì—|ì´)?\s*(?:í¬í•¨ëœ|ìˆëŠ”)?\s*|.*?\s*)\s*([^\s]+)", query)
    if title_pattern:
        keyword = title_pattern.group(2).strip()
        if keyword:
            title_keyword = keyword
            print(f"ğŸ” ì œëª© í‚¤ì›Œë“œ ê°ì§€: '{keyword}' (Python í›„ì²˜ë¦¬ ì˜ˆì •)")

    # --- B. ë‚ ì§œ í•„í„°ë§ ë¡œì§: 'YYYY-MM-DD' í˜•ì‹ì˜ ë©”íƒ€ë°ì´í„° 'date' í•„ë“œì— ì ìš© ---

    # íŒ¨í„´ 1: 'YYYYë…„ ì´í›„' / 'YYYYë…„ë„ ì´í›„' (ê¸°ì¡´)
    after_year_pattern = re.search(r"(\d{4})ë…„(?:ë„)?\s*ì´í›„", query)
    if after_year_pattern:
        year = int(after_year_pattern.group(1))
        start_date_utc = datetime(year, 1, 1, 0, 0, 0, tzinfo=timezone.utc)
        start_timestamp = start_date_utc.timestamp()
        where_conditions.append({"date": {"$gte": start_timestamp}})

    # íŒ¨í„´ 2: 'YYYYë…„ MMì›” ë‚´' / 'YYYYë…„ MMì›”ê¹Œì§€' (ê¸°ì¡´)
    within_month_pattern = re.search(r"(\d{4})ë…„\s*(\d{1,2})ì›”\s*(?:ì´ë‚´|ë‚´|ê¹Œì§€)", query)
    if within_month_pattern:
        year = int(within_month_pattern.group(1))
        month = int(within_month_pattern.group(2))

        if month == 12:
            next_month_start = datetime(year + 1, 1, 1, 0, 0, 0, tzinfo=timezone.utc)
        else:
            next_month_start = datetime(year, month + 1, 1, 0, 0, 0, tzinfo=timezone.utc)

        end_timestamp_exclusive = next_month_start.timestamp()
        where_conditions.append({"date": {"$lt": end_timestamp_exclusive}})

    # --- B-1. âœ… ì¶”ê°€ëœ ë¡œì§: 'ì§€ë‚œ Xê°œì›”' / 'ì§€ë‚œ Xë…„' ---

    # íŒ¨í„´ 3: 'ì§€ë‚œ Xê°œì›”'
    last_months_pattern = re.search(r"ì§€ë‚œ\s*(\d+)\s*ê°œì›”", query)
    if last_months_pattern:
        months = int(last_months_pattern.group(1))
        # relativedeltaë¥¼ ì‚¬ìš©í•˜ì—¬ Xê°œì›” ì „ ì‹œì ì„ ì •í™•íˆ ê³„ì‚°
        start_date_limit = now_utc - relativedelta(months=months)
        start_timestamp = start_date_limit.timestamp()
        where_conditions.append({"date": {"$gte": start_timestamp}})
        print(f"âœ… ë‚ ì§œ í•„í„° ê°ì§€: ì§€ë‚œ {months}ê°œì›” (UTC ê¸°ì¤€: {start_date_limit.strftime('%Y-%m-%d %H:%M')})")

    # íŒ¨í„´ 4: 'ì§€ë‚œ Xë…„'
    last_years_pattern = re.search(r"ì§€ë‚œ\s*(\d+)\s*ë…„", query)
    if last_years_pattern:
        years = int(last_years_pattern.group(1))
        # relativedeltaë¥¼ ì‚¬ìš©í•˜ì—¬ Xë…„ ì „ ì‹œì ì„ ì •í™•íˆ ê³„ì‚°
        start_date_limit = now_utc - relativedelta(years=years)
        start_timestamp = start_date_limit.timestamp()
        where_conditions.append({"date": {"$gte": start_timestamp}})
        print(f"âœ… ë‚ ì§œ í•„í„° ê°ì§€: ì§€ë‚œ {years}ë…„ (UTC ê¸°ì¤€: {start_date_limit.strftime('%Y-%m-%d %H:%M')})")

    # --- C. ìµœì¢… í•„í„° êµ¬ì¡° ì¡°ë¦½ (ê¸°ì¡´ê³¼ ë™ì¼) ---

    if where_conditions:
        if len(where_conditions) == 1:
            search_kwargs["where"] = where_conditions[0]
        else:
            search_kwargs["where"] = {"$and": where_conditions}

    # ìµœì¢… í•„í„°ì™€ ì œëª© í‚¤ì›Œë“œ ë°˜í™˜
    return (search_kwargs if search_kwargs else None, title_keyword)


# ---------- ë‹µë³€ ìƒì„± (invoke ì‚¬ìš©) ----------
@logging_time
def get_answer(qa, db, query: str):
    global USE_RERANKER, INITIAL_K, FINAL_K  # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš© ì„ ì–¸

    # 1. ì§ˆë¬¸ì—ì„œ ë©”íƒ€ë°ì´í„° í•„í„°ì™€ ì œëª© í‚¤ì›Œë“œë¥¼ ì¶”ì¶œ
    metadata_filter, title_keyword = extract_chroma_filter(query)

    # 2. ê²€ìƒ‰ ì¸ì ì„¤ì • (K ê°’ì€ INITIAL_K ì‚¬ìš©)
    current_k = INITIAL_K

    # 3. ë¬¸ì„œ ê²€ìƒ‰: ChromaDBì˜ raw APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚ ì§œ í•„í„°ë§ë§Œ ì ìš©
    try:
        if metadata_filter and 'where' in metadata_filter:
            where_condition = metadata_filter['where']
            print(f"âœ… ChromaDB ë‚ ì§œ í•„í„°ë§: K={current_k}, Where={where_condition}")
            docs = db.similarity_search(
                query=query,
                k=current_k,
                filter=where_condition
            )
        else:
            # í•„í„°ê°€ ì—†ëŠ” ê²½ìš°: ìœ ì‚¬ë„ ê²€ìƒ‰ë§Œ ìˆ˜í–‰
            docs = db.similarity_search(
                query=query,
                k=current_k
            )

    except Exception as e:
        print(f"âš ï¸ ChromaDB ê²€ìƒ‰ ì˜¤ë¥˜ ë°œìƒ. í•„í„° ì—†ì´ ì¬ì‹œë„: {e}")
        docs = db.similarity_search(query=query, k=current_k)

    # 4. ì œëª© í‚¤ì›Œë“œë¡œ Pythonì—ì„œ í›„ì²˜ë¦¬ í•„í„°ë§ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    if title_keyword:
        original_count = len(docs)
        keyword_lower = title_keyword.lower().strip()
        filtered_docs = []
        for d in docs:
            title = d.metadata.get('title', '').lower().strip()
            if keyword_lower in title:
                filtered_docs.append(d)
            else:
                print(f"  âŒ ì œì™¸ëœ ì œëª©: '{d.metadata.get('title', '')}' (í‚¤ì›Œë“œ '{title_keyword}' ì—†ìŒ)")
        docs = filtered_docs
        print(f"ğŸ” ì œëª© '{title_keyword}' í•„í„° ì ìš©: {original_count}ê°œ â†’ {len(docs)}ê°œ ë¬¸ì„œ")

    # 5. ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš° ì¡°ê¸° ë°˜í™˜
    # 5. ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš° ì¡°ê¸° ë°˜í™˜
    if not docs:
        return "ê²€ìƒ‰ ì¡°ê±´ì— ë§ëŠ” ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

    # âœ… 5-1. íŒŒì¼ ì €ì¥ ë¡œì§ ìˆ˜ì •: ì‚¬ìš©ì ì§€ì • ê²½ë¡œ ë° íŒŒì¼ëª…ì— ì§ˆë¬¸ ë‚´ìš© ë°˜ì˜
    try:
        # 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •: Pathlib ì‚¬ìš© (importëŠ” íŒŒì¼ ìƒë‹¨ì— ìˆë‹¤ê³  ê°€ì •)
        import os
        from pathlib import Path

        # ìŠ¤í¬ë¦½íŠ¸ê°€ ì‹¤í–‰ë˜ëŠ” ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ 'data' í´ë” ì„¤ì •
        script_dir = Path(__file__).parent
        data_dir = script_dir / "data"

        # 2. ì§ˆë¬¸ì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±° ë° ê¸¸ì´ ì œí•œ
        # íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        safe_query = re.sub(r'[\\/:*?"<>|]', '', query).strip()

        # íŒŒì¼ëª… ê¸¸ì´ ì œí•œ (ì˜ˆ: 50ì)
        file_name_base = safe_query[:50] if len(safe_query) > 50 else safe_query

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # 3. ìµœì¢… íŒŒì¼ ê²½ë¡œ ì„¤ì • ë° í´ë” ìƒì„±
        # 'data' í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„± (exist_ok=Trueë¡œ ê¶Œí•œ ì˜¤ë¥˜ ì¼ë¶€ ë°©ì§€)
        data_dir.mkdir(parents=True, exist_ok=True)

        file_name = f"{file_name_base}_{timestamp}.txt"
        file_path = data_dir / file_name  # ìµœì¢… íŒŒì¼ ê²½ë¡œ: [ìŠ¤í¬ë¦½íŠ¸ê²½ë¡œ]/data/[ì§ˆë¬¸_íƒ€ì„ìŠ¤íƒ¬í”„].txt

        # 4. íŒŒì¼ ë‚´ìš© ìƒì„±
        file_content = f"--- RAG Initial Retrieval Log ---\n"
        file_content += f"Query: {query}\n"
        file_content += f"Initial K: {INITIAL_K}\n"
        file_content += f"Documents Retrieved: {len(docs)}\n"
        file_content += "---------------------------------------\n\n"

        # 5. ë¬¸ì„œ ë‚´ìš© ëª©ë¡ ì¶”ê°€
        for i, d in enumerate(docs, 1):
            title = d.metadata.get("title", "ì œëª© ì—†ìŒ")
            date_str = conv_timestamp(d.metadata.get("date", "ë‚ ì§œ ì—†ìŒ"))
            source = d.metadata.get("source", "ì¶œì²˜ ì—†ìŒ")

            file_content += f"[{i}] Title: {title}\n"
            file_content += f"    Date: {date_str}, Source: {source}\n"
            file_content += f"    Content Snippet (First 500 chars):\n"

            # f-string ì˜¤ë¥˜ í•´ê²°: replace('\n', ' ')ë¥¼ ë¨¼ì € ë³€ìˆ˜ì— ì €ì¥
            replaced_content = d.page_content[:500].replace('\n', ' ')
            file_content += f"    {replaced_content}...\n\n"

            file_content += "---\n"

        # 6. íŒŒì¼ ì“°ê¸°
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(file_content)

        print(f"\nğŸ’¾ ê²€ìƒ‰ëœ {len(docs)}ê°œ ë¬¸ì„œ ëª©ë¡ì„ íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤: {file_path}")

    except Exception as e:
        print(f"\nâš ï¸ ë¬¸ì„œ ëª©ë¡ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    # 6. âœ… ì¬ìˆœìœ„í™” ë¡œì§ ì ìš© (ì„ íƒ ì‚¬í•­)
    if USE_RERANKER:
        print(f"--- ğŸ”„ ì¬ìˆœìœ„í™” ì‹œì‘ (Total {len(docs)}ê°œ ë¬¸ì„œ) ---")
        reranked_results = rerank_documents(query, docs, top_k=FINAL_K)

        # ì¬ìˆœìœ„í™” ê²°ê³¼ì—ì„œ ë‹¤ì‹œ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (LLM ì…ë ¥ í˜•ì‹ ë§ì¶¤)
        docs = [
            Document(
                page_content=d['content'],
                metadata={**d['metadata'], 'rerank_score': d['rerank_score']}
            )
            for d in reranked_results
        ]
        print(f"--- âœ… ìµœì¢… {len(docs)}ê°œ ë¬¸ì„œ ë°˜í™˜ (Reranked) ---")
    else:
        # ì¬ìˆœìœ„í™” ê±´ë„ˆë›°ê¸°: ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ì—ì„œ FINAL_Kê°œë§Œ ì‚¬ìš©
        docs = docs[:FINAL_K]
        print(f"--- âœ… ìµœì¢… {len(docs)}ê°œ ë¬¸ì„œ ë°˜í™˜ (Initial Top-K) ---")

    # 7. ë””ë²„ê¹…ìš©: ê²€ìƒ‰ëœ context ê°„ë‹¨ ì¶œë ¥
    context_parts = []
    print("\nğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ(ìš”ì•½):")
    for i, d in enumerate(docs, 1):
        title = d.metadata.get("title", "ì œëª© ì—†ìŒ")
        date_str = conv_timestamp(d.metadata.get("date", "ë‚ ì§œ ì—†ìŒ"))
        source = d.metadata.get("source", "ì¶œì²˜ ì—†ìŒ")
        snippet = d.page_content[:200].replace("\n", " ")
        score_info = f"[Score: {d.metadata.get('rerank_score', 'N/A'):.4f}]" if 'rerank_score' in d.metadata else ""

        print(f"  {score_info} [{i}] {title} / {date_str} / {source}\n       {snippet}...\n")
        context_part = (
                d.page_content +
                f" (ì œëª©: {d.metadata.get('title', 'N/A')}, ê²Œì‹œì¼: {date_str}, Score: {score_info})"
        )
        context_parts.append(context_part)

    # 8. LLM ë‹µë³€ ìƒì„±
    context = "\n\n---\n\n".join(context_parts)
    final_prompt = PROMPT_TEMPLATE.format(context=context, question=query)

    llm = load_llm(gpu_acceleration=use_gpu)
    try:
        response = llm.invoke(final_prompt)
        return response, docs
    except Exception as e:
        return f"LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}", docs


# ---------- ë©”ì¸ (ê¸°ì¡´ê³¼ ë™ì¼) ----------
def main():
    print("ğŸ¤– ê²Œì‹œíŒ ê¸°ë°˜ ì±—ë´‡ (Ctrl+C ë¡œ ì¢…ë£Œ)\n")
    global use_gpu, USE_RERANKER, INITIAL_K, FINAL_K  # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš© ì„ ì–¸

    # --- ì „ì—­ ì˜µì…˜ ì„¤ì • ---
    use_gpu_input = input("ğŸ’¡ GPU ê°€ì†ì„ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
    use_gpu = use_gpu_input == 'y'

    # ì¬ìˆœìœ„í™” ì˜µì…˜ ì…ë ¥ ë°›ê¸°
    rerank_input = input(f"â­ ì¬ìˆœìœ„í™”(Reranking)ë¥¼ ì‚¬ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n, ê¸°ë³¸={USE_RERANKER}): ").strip().lower()
    USE_RERANKER = rerank_input == 'y'

    # K ê°’ ì¡°ì • ì˜µì…˜
    if USE_RERANKER:
        try:
            initial_k_input = input(f"ğŸ” ì´ˆê¸° ê²€ìƒ‰ Kê°’ (ê¸°ë³¸={INITIAL_K}): ").strip()
            if initial_k_input:
                INITIAL_K = int(initial_k_input)

            final_k_input = input(f"âœ… ìµœì¢… ë°˜í™˜ Kê°’ (ê¸°ë³¸={FINAL_K}): ").strip()
            if final_k_input:
                FINAL_K = int(final_k_input)

        except ValueError:
            print("â— Kê°’ ì„¤ì •ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì¬ì„¤ì •í•©ë‹ˆë‹¤.")
            INITIAL_K = 100
            FINAL_K = 10

    else:
        # Rerankë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ KëŠ” FINAL_K ê°’ë§Œ ê°€ì§
        INITIAL_K = FINAL_K

    print(f"\n** RAG ì„¤ì •: Reranker={USE_RERANKER}, K_init={INITIAL_K}, K_final={FINAL_K} **")
    # --- ì˜µì…˜ ì„¤ì • ì™„ë£Œ ---

    qa, db, retriever = create_qa_chain(gpu_acceleration=use_gpu)

    while True:
        try:
            query = input("ğŸ—¨ï¸ ì§ˆë¬¸: ").strip()
            if not query:
                continue

            response, docs = get_answer(qa, db, query)

            print("\nğŸ’¬ ë‹µë³€:\n", response)

            print("\nğŸ“š ì°¸ê³  ë¬¸ì„œ ëª©ë¡:")
            for i, d in enumerate(docs, 1):
                date_str = conv_timestamp(d.metadata.get('date', None))
                score_info = f" | Rerank Score: {d.metadata.get('rerank_score', 'N/A'):.4f}" if 'rerank_score' in d.metadata else ""
                print(
                    f"  [{i}] ì œëª©: {d.metadata.get('title', 'ì•Œ ìˆ˜ ì—†ìŒ')} / ë‚ ì§œ: {date_str} / ì¶œì²˜: {d.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')}{score_info}")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break


def conv_timestamp(timestamp):
    date_str = 'ì•Œ ìˆ˜ ì—†ìŒ'
    if isinstance(timestamp, (int, float)) and timestamp > 0:
        try:
            date_str = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
        except Exception:
            date_str = 'ë³€í™˜ ì˜¤ë¥˜'
    return date_str


if __name__ == "__main__":
    main()