# make_vector_db.py
import os
import json
from pathlib import Path
from tqdm import tqdm
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.schema import Document
from commonUtil.timeCheck import logging_time


def extract_text_from_file(file_path: str) -> dict:
    """íŒŒì¼ì„ ì½ì–´ JSONì´ë©´ ë³€í™˜, ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ í…ìŠ¤íŠ¸ ë¦¬í„´"""
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read().strip()

    if not content:
        return ""

    if content.startswith("{") and content.endswith("}"):
        try:
            data = json.loads(content)
            title = data.get("ì œëª©", "")
            body = data.get("ë³¸ë¬¸", "")
            author = data.get("ê²Œì‹œì", "")
            date = data.get("ê²Œì‹œì¼ì‹œ", "")

            text = f"ì œëª©: {title}\në‚´ìš©: {body}\nê²Œì‹œì: {author}\nê²Œì‹œì¼ì‹œ: {date}"

            return {
                "text": text.strip(),
                "date": date,
                "title": title,
                "body": body
            }

        except Exception:
            return {"text": content, "date": "", "title": "", "body": ""}
    else:
        return {"text": content, "date": "", "title": "", "body": ""}


def load_documents_from_folder(folder_path: str):
    """í´ë” ë‚´ ëª¨ë“  txt íŒŒì¼ì„ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë¡œë“œ"""
    documents = []

    print("ğŸ” Scanning for .txt files...")
    all_txt_files = [
        os.path.join(root, f)
        for root, _, files in os.walk(folder_path)
        for f in files if f.lower().endswith(".txt")
    ]

    if not all_txt_files:
        print("âš ï¸ No .txt files found.")
        return documents

    print(f"ğŸ“Š Found {len(all_txt_files)} .txt files\n")

    for file_path in tqdm(all_txt_files, desc="ğŸ“– Loading & parsing files", unit="file"):
        try:
            result = extract_text_from_file(file_path)

            text = result["text"]
            date = result["date"]
            title = result["title"]
            body = result["body"]

            if not text:
                tqdm.write(f"  âš ï¸ Empty file skipped: {file_path}")
                continue

            # âœ… ë³¸ë¬¸ ë¬¸ì„œ
            doc_body = Document(
                page_content=text,
                metadata={
                    "source": file_path,
                    "date": date,
                    "title": title,
                    "type": "body"
                },
            )

            # âœ… ì œëª© ì „ìš© ë¬¸ì„œ (NEW)
            if title:
                doc_title = Document(
                    page_content=title,
                    metadata={
                        "source": file_path,
                        "date": date,
                        "title": title,
                        "type": "title"
                    },
                )
                documents.extend([doc_body, doc_title])
            else:
                documents.append(doc_body)

            rel_path = os.path.relpath(file_path, folder_path)
            tqdm.write(f"  âœ… {rel_path} ({len(text)} chars, title added: {'Y' if title else 'N'})")

        except Exception as e:
            tqdm.write(f"  âŒ Error reading {file_path}: {e}")

    print(f"\nâœ¨ Successfully loaded: {len(documents)} entries (body + title í¬í•¨)")
    return documents


@logging_time
def create_vector_db(folder_path, persist_dir="./chroma_db2"):
    print(f"\n{'=' * 60}")
    print(f"ğŸ“‚ Target folder: {folder_path}")
    print(f"ğŸ’¾ Vector DB will be saved to: {persist_dir}")
    print(f"{'=' * 60}\n")

    documents = load_documents_from_folder(folder_path)

    if not documents:
        print("âš ï¸ No valid .txt or JSON files found. Aborting.")
        return None

    avg_length = sum(len(doc.page_content) for doc in documents) / len(documents)
    print(f"ğŸ“Š Average text length: {avg_length:.1f} chars")

    print("\nğŸ” Creating embeddings (this may take a while)...")
    embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")
    # ì§‘ ë©”ì¸ pc ìš©
    # embeddings = HuggingFaceEmbeddings(
    #     model_name="upskyy/gte-base-korean",
    #     model_kwargs={'trust_remote_code': True}
    # )

    print("ğŸ’¾ Saving to Chroma vector DB...")
    db = Chroma.from_documents(documents, embeddings, persist_directory=persist_dir)

    print(f"\n{'=' * 60}")
    print(f"âœ… Vector DB successfully created!")
    print(f"ğŸ“ Location: {persist_dir}")
    print(f"ğŸ“Š Total embedded entries: {len(documents)} (body + title í¬í•¨)")
    print(f"ğŸ“ˆ Average text length: {avg_length:.1f} chars")
    print(f"{'=' * 60}")
    return db


if __name__ == "__main__":
    folder_path = input("ğŸ“ Enter folder path containing TXT files: ").strip()

    if not os.path.exists(folder_path):
        print(f"âŒ Error: Folder '{folder_path}' does not exist!")
    elif not os.path.isdir(folder_path):
        print(f"âŒ Error: '{folder_path}' is not a directory!")
    else:
        create_vector_db(folder_path)
