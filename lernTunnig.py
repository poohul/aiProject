# hil_data_collector_multi_pair.py (Positive/Negative ë³µìˆ˜ ì„ íƒ ëª¨ë“œ)
import re
import json
import time
from typing import Dict, Any, List, Union, Set  # Set íƒ€ì… íŒíŠ¸ ì¶”ê°€
from datetime import datetime, timezone
from dateutil.relativedelta import relativedelta
from pathlib import Path

# --- RAG ì„¤ì • ìƒìˆ˜ ---
DB_FOLDER = "./chroma_db3"
INITIAL_K = 200
# ----------------------

# --- í•™ìŠµ ë°ì´í„° ì €ì¥ ê²½ë¡œ ---
HIL_DATA_DIR = Path("./hil_training_data")
# ------------------------------

# --- Langchain Imports ---
try:
    from langchain_chroma import Chroma
except Exception:
    from langchain_community.vectorstores import Chroma

try:
    from langchain_huggingface import HuggingFaceEmbeddings
except Exception:
    try:
        from langchain_community.embeddings import HuggingFaceEmbeddings
    except Exception:
        raise ImportError("HuggingFaceEmbeddings import failed. Check dependencies.")

# --- ì „ì—­ ë³€ìˆ˜
use_gpu = False


# ---------- ë²¡í„° DB ë¡œë“œ ----------
def load_vector_db(persist_dir: str = DB_FOLDER):
    """ë²¡í„° DB(Chroma)ì™€ ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    # ì‹¤ì œ ì„ë² ë”© ëª¨ë¸ ì´ë¦„ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. (ì´ì „ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‚¬ìš©ëœ ì´ë¦„)
    embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")
    db = Chroma(persist_directory=persist_dir, embedding_function=embeddings)
    return db


# ---------- íƒ€ì„ìŠ¤íƒ¬í”„ ë³€í™˜ í•¨ìˆ˜ ----------
def conv_timestamp(timestamp: Union[int, float, str]) -> str:
    """íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ YYYY-MM-DD í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    date_str = 'ì•Œ ìˆ˜ ì—†ìŒ'
    if isinstance(timestamp, (int, float)) and timestamp > 0:
        try:
            # UTC íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë¡œì»¬ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
            date_str = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')
        except Exception:
            date_str = 'ë³€í™˜ ì˜¤ë¥˜'
    return date_str


# ---------- í•„í„° ì¶”ì¶œ í•¨ìˆ˜ ----------
def extract_chroma_filter(query: str) -> tuple[Union[Dict[str, Any], None], Union[str, None]]:
    """ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ChromaDB ê²€ìƒ‰ì„ ìœ„í•œ í•„í„°ë§ ì¸ìë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    now_utc = datetime.now(timezone.utc)
    where_conditions: List[Dict[str, Any]] = []
    search_kwargs: Dict[str, Any] = {}
    title_keyword = None

    # A. ì œëª© í•„í„°ë§ ë¡œì§
    title_pattern = re.search(r"(ì œëª©|íƒ€ì´í‹€)[^\s]*\s*(?:(?:ì—|ì´)?\s*(?:í¬í•¨ëœ|ìˆëŠ”)?\s*|.*?\s*)\s*([^\s]+)", query)
    if title_pattern:
        keyword = title_pattern.group(2).strip()
        if keyword:
            title_keyword = keyword

    # B. ë‚ ì§œ í•„í„°ë§ ë¡œì§ (GTE, LT ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„)
    after_year_pattern = re.search(r"(\d{4})ë…„(?:ë„)?\s*ì´í›„", query)
    if after_year_pattern:
        year = int(after_year_pattern.group(1))
        start_date_utc = datetime(year, 1, 1, 0, 0, 0, tzinfo=timezone.utc)
        start_timestamp = start_date_utc.timestamp()
        where_conditions.append({"date": {"$gte": start_timestamp}})

    within_month_pattern = re.search(r"(\d{4})ë…„\s*(\d{1,2})ì›”\s*(?:ì´ë‚´|ë‚´|ê¹Œì§€)", query)
    if within_month_pattern:
        year = int(within_month_pattern.group(1))
        month = int(within_month_pattern.group(2))
        next_month_start = datetime(year, month + 1, 1, 0, 0, 0, tzinfo=timezone.utc) if month < 12 else datetime(
            year + 1, 1, 1, 0, 0, 0, tzinfo=timezone.utc)
        end_timestamp_exclusive = next_month_start.timestamp()
        where_conditions.append({"date": {"$lt": end_timestamp_exclusive}})

    last_months_pattern = re.search(r"ì§€ë‚œ\s*(\d+)\s*ê°œì›”", query)
    if last_months_pattern:
        months = int(last_months_pattern.group(1))
        start_date_limit = now_utc - relativedelta(months=months)
        start_timestamp = start_date_limit.timestamp()
        where_conditions.append({"date": {"$gte": start_timestamp}})

    last_years_pattern = re.search(r"ì§€ë‚œ\s*(\d+)\s*ë…„", query)
    if last_years_pattern:
        years = int(last_years_pattern.group(1))
        start_date_limit = now_utc - relativedelta(years=years)
        start_timestamp = start_date_limit.timestamp()
        where_conditions.append({"date": {"$gte": start_timestamp}})

    # C. ìµœì¢… í•„í„° êµ¬ì¡° ì¡°ë¦½
    if where_conditions:
        search_kwargs["where"] = where_conditions[0] if len(where_conditions) == 1 else {"$and": where_conditions}

    return (search_kwargs if search_kwargs else None, title_keyword)


# ---------- HIL ë°ì´í„° ìˆ˜ì§‘ ë©”ì¸ ë¡œì§ (ë³µìˆ˜ ìŒ ëª¨ë“œ) ----------
def interactive_labeling_mode(db, query: str):
    """
    ì‚¬ìš©ìì—ê²Œ Positive ë¬¸ì„œì™€ Negative ë¬¸ì„œë¥¼ ë³µìˆ˜ë¡œ ì„ íƒí•˜ë„ë¡ ìœ ë„í•˜ì—¬ íŠ¸ë¦½ë ›ì„ ì €ì¥í•©ë‹ˆë‹¤.
    """

    # 1-3. ë¬¸ì„œ ê²€ìƒ‰ ë° í•„í„°ë§
    metadata_filter, title_keyword = extract_chroma_filter(query)
    current_k = INITIAL_K

    try:
        if metadata_filter and 'where' in metadata_filter:
            where_condition = metadata_filter['where']
            docs = db.similarity_search(query=query, k=current_k, filter=where_condition)
        else:
            docs = db.similarity_search(query=query, k=current_k)

    except Exception as e:
        print(f"âš ï¸ ChromaDB ê²€ìƒ‰ ì˜¤ë¥˜ ë°œìƒ. í•„í„° ì—†ì´ ì¬ì‹œë„: {e}")
        docs = db.similarity_search(query=query, k=current_k)

    if title_keyword:
        original_count = len(docs)
        keyword_lower = title_keyword.lower().strip()
        filtered_docs = [d for d in docs if keyword_lower in d.metadata.get('title', '').lower().strip()]
        docs = filtered_docs
        print(f"ğŸ” ì œëª© '{title_keyword}' í•„í„° ì ìš©: {original_count}ê°œ â†’ {len(docs)}ê°œ ë¬¸ì„œ")

    if not docs:
        print("ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ì–´ ë¼ë²¨ë§ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\n--- ğŸ§  Active Learning: ì •ë‹µ/ì˜¤ë‹µ ë¬¸ì„œ ë³µìˆ˜ ì„ íƒ ({len(docs)}ê°œ ì¤‘) ---")

    # 4. ì‚¬ìš©ìì—ê²Œ ë¬¸ì„œ ëª©ë¡ ë³´ì—¬ì£¼ê¸°
    for i, d in enumerate(docs, 1):
        title = d.metadata.get("title", "ì œëª© ì—†ìŒ")
        date_str = conv_timestamp(d.metadata.get("date", "ë‚ ì§œ ì—†ìŒ"))
        source = d.metadata.get("source", "ì¶œì²˜ ì—†ìŒ")
        snippet = d.page_content[:100].replace("\n", " ")
        print(f"[{i}] ì œëª©: {title} | ë‚ ì§œ: {date_str} | ì¶œì²˜: {source} | ë‚´ìš©: {snippet}...")

    # 5. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° - Positive/Negative ë³µìˆ˜ ì„ íƒ
    try:
        def get_indices(prompt: str) -> List[int]:
            """ì½¤ë§ˆ êµ¬ë¶„ì ì…ë ¥ì„ ë°›ì•„ ìœ íš¨í•œ ë¬¸ì„œ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
            selection = input(prompt).strip()
            if not selection or selection == '0':
                return []

            indices: Set[int] = set()
            for s in selection.split(','):
                try:
                    idx = int(s.strip()) - 1
                    if 0 <= idx < len(docs):
                        indices.add(idx)
                    else:
                        print(f"ê²½ê³ : ìœ íš¨í•˜ì§€ ì•Šì€ ë²ˆí˜¸ '{s.strip()}'ëŠ” ë¬´ì‹œë˜ì—ˆìŠµë‹ˆë‹¤.")
                except ValueError:
                    pass
            return sorted(list(indices))

        # 5a. Positive ë¬¸ì„œ ì„ íƒ
        pos_indices = get_indices("\nğŸ’¡ 1. **ì •ë‹µ(Positive)** ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 1,2,5 / ì·¨ì†Œ: 0): ")
        if not pos_indices:
            print("Positive ë¬¸ì„œ ì„ íƒ ì·¨ì†Œ.")
            return

        # 5b. Negative ë¬¸ì„œ ì„ íƒ
        neg_indices = get_indices("ğŸ’¡ 2. **ì˜¤ë‹µ(Negative)** ë¬¸ì„œ ë²ˆí˜¸ë¥¼ ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 8,10,12 / ì·¨ì†Œ: 0): ")

        # 6. ìœ íš¨ì„± ê²€ì‚¬ ë° ë°ì´í„° ì¶”ì¶œ

        # Positive/Negative ì¤‘ë³µ ì„ íƒ í™•ì¸
        pos_set = set(pos_indices)
        neg_set = set(neg_indices)

        if pos_set.intersection(neg_set):
            print("ğŸš¨ ì˜¤ë¥˜: Positiveì™€ Negativeë¡œ ì¤‘ë³µ ì„ íƒëœ ë¬¸ì„œê°€ ìˆìŠµë‹ˆë‹¤. ë¼ë²¨ë§ ì·¨ì†Œ.")
            return

        if not neg_indices:
            print("ê²½ê³ : Negative ë¬¸ì„œê°€ ì„ íƒë˜ì§€ ì•Šì•„, Positive-Only ìŒìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.")

        positive_docs = [docs[idx] for idx in pos_indices]
        negative_docs = [docs[idx] for idx in neg_indices]

        print(f"\nâœ… Positive ë¬¸ì„œ {len(positive_docs)}ê°œ ì„ íƒë¨.")
        print(f"âŒ Negative ë¬¸ì„œ {len(negative_docs)}ê°œ ì„ íƒë¨.")

        # 7. íŠ¸ë¦½ë › ë°ì´í„° ì €ì¥
        HIL_DATA_DIR.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # íŒŒì¼ëª… ì•ˆì „ ì²˜ë¦¬
        safe_query = re.sub(r'[\\/:*?"<>|]', '', query).strip()[:30]
        data_file = HIL_DATA_DIR / f"triplet_multi_{safe_query}_{timestamp}.json"

        # ì €ì¥í•  ë°ì´í„° êµ¬ì¡°
        triplet_data: Dict[str, Any] = {
            "query": query,
            "positive": [
                {
                    "content": d.page_content,
                    "title": d.metadata.get("title", "N/A"),
                    "source": d.metadata.get("source", "N/A"),
                } for d in positive_docs
            ],
            "negatives": [
                {
                    "content": d.page_content,
                    "title": d.metadata.get("title", "N/A")
                } for d in negative_docs
            ]
        }

        # Positive í•„ë“œë¥¼ ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥í•˜ë„ë¡ êµ¬ì¡° ë³€ê²½
        if len(positive_docs) == 1:
            # ì´ì „ í¬ë§·ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ 1ê°œì¼ ë•ŒëŠ” ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
            triplet_data['positive'] = triplet_data['positive'][0]

        with open(data_file, 'w', encoding='utf-8') as f:
            json.dump(triplet_data, f, ensure_ascii=False, indent=4)

        print(f"ğŸ’¾ í•™ìŠµ ë°ì´í„° íŠ¸ë¦½ë ›(N:M ìŒ)ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {data_file}")

    except Exception as e:
        print(f"âš ï¸ ë°ì´í„° ì²˜ë¦¬/ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# ---------- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (HIL ëª¨ë“œ ì „ìš©) ----------
def main():
    print("ğŸ§  ëŠ¥ë™ í•™ìŠµ(HIL) ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“œ ì‹œì‘ (Positive/Negative ë³µìˆ˜ ì„ íƒ)")

    db = load_vector_db()

    while True:
        try:
            query = input("ğŸ—¨ï¸ í•™ìŠµ ë°ì´í„°ë¡œ ë§Œë“¤ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (Ctrl+C ë¡œ ì¢…ë£Œ): ").strip()
            if not query:
                continue

            interactive_labeling_mode(db, query)

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ë°ì´í„° ìˆ˜ì§‘ ëª¨ë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break


if __name__ == "__main__":
    main()