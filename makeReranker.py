# reranker_finetuner.py
import json
from pathlib import Path
import torch
from torch import nn
from torch.utils.data import DataLoader
from sentence_transformers import CrossEncoder, InputExample
import re
from typing import List, Dict, Any, Union # ğŸ‘ˆ Union, List, Dict, Anyë¥¼ importí•©ë‹ˆë‹¤.

# 1. ì„¤ì •
RERANKER_NAME = 'cross-encoder/ms-marco-TinyBERT-L-2'  # ê¸°ë³¸ ëª¨ë¸ë¡œ ì¬ì‹œì‘ ê¶Œì¥
HIL_DATA_DIR = Path("./hil_training_data")
OUTPUT_MODEL_PATH = './custom_kyoboDTS_bbs_reranker'  # ìƒˆë¡œìš´ ê²½ë¡œ ê¶Œì¥
# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
BATCH_SIZE = 16
NUM_EPOCHS = 3
LEARNING_RATE = 2e-5

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ì„¤ì •
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"Using device: {device}")

# ğŸ“… ë‚ ì§œ íŒ¨í„´: YYYY.MM.DD ë˜ëŠ” YYYY-MM-DD í˜•íƒœë¥¼ ê°ì§€í•˜ëŠ” ì •ê·œì‹
DATE_PATTERN = re.compile(r'\d{4}[.\s-]\d{2}[.\s-]\d{2}')


def clean_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ íŒ¨í„´ì„ ì œê±°í•˜ê³  ë¶ˆí•„ìš”í•œ ê³µë°±ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
    if not isinstance(text, str):
        return ""
    # ë‚ ì§œ íŒ¨í„´ì„ ì°¾ì•„ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
    text = DATE_PATTERN.sub(' ', text)
    # ì¤‘ë³µëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì¤„ì—¬ì„œ í…ìŠ¤íŠ¸ë¥¼ ê¹”ë”í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
    return ' '.join(text.split()).strip()


# 2. ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„
def load_and_prepare_data(data_dir: Path) -> List[InputExample]:
    """
    ì €ì¥ëœ JSON íŠ¸ë¦½ë › ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  InputExample ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    (ë³µìˆ˜ Positive/Negative ë¬¸ì„œ ì§€ì›)
    """
    train_examples = []

    for json_file in data_dir.glob("triplet_*.json"):
        with open(json_file, 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
            except json.JSONDecodeError:
                print(f"âš ï¸ JSON Decode Error in file: {json_file}. Skipping.")
                continue

        query = data.get('query', '')
        if not query:
            continue

        # Positive ë¬¸ì„œ ì²˜ë¦¬ (ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë‹¨ì¼ ë”•ì…”ë„ˆë¦¬ ëª¨ë‘ ì²˜ë¦¬)
        positives: Union[List[Dict[str, Any]], Dict[str, Any], None] = data.get('positive')
        if not positives:
            continue  # Positive ë¬¸ì„œê°€ ì—†ëŠ” íŠ¸ë¦½ë ›ì€ í•™ìŠµ ìŒì„ ë§Œë“¤ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ê±´ë„ˆëœë‹ˆë‹¤.

        if isinstance(positives, dict):
            # ë‹¨ì¼ Positive í¬ë§·ì¸ ê²½ìš°, ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬ í†µì¼
            pos_list = [positives]
        elif isinstance(positives, list):
            pos_list = positives
        else:
            continue  # ì´ìƒí•œ íƒ€ì…ì€ ê±´ë„ˆëœë‹ˆë‹¤.

        # ê¸ì • ìŒ (Positive Pair) ì¶”ê°€: ë ˆì´ë¸” 1.0 (ë§¤ìš° ê´€ë ¨ ìˆìŒ)
        for pos in pos_list:
            pos_content = clean_text(pos.get('content', ''))
            if pos_content:
                train_examples.append(InputExample(texts=[query, pos_content], label=1.0))

        # ë¶€ì • ìŒ (Negative Pairs) ì¶”ê°€: ë ˆì´ë¸” 0.0 (ê´€ë ¨ ì—†ìŒ)
        negatives: List[Dict[str, Any]] = data.get('negatives', [])
        for neg in negatives:
            neg_content = clean_text(neg.get('content', ''))
            if neg_content:
                train_examples.append(InputExample(texts=[query, neg_content], label=0.0))

    if not train_examples:
        print("í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ íŒŒì¸íŠœë‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"ğŸ’¾ ì´ {len(train_examples)}ê°œì˜ í•™ìŠµ ìŒì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.")

    return train_examples


# 3. ëª¨ë¸ íŒŒì¸íŠœë‹ í•¨ìˆ˜
def fine_tune_reranker():
    # ë°ì´í„° ë¡œë“œ
    train_examples = load_and_prepare_data(HIL_DATA_DIR)
    if not train_examples:
        return

    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)

    # ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš© ì„¤ì •)
    model = CrossEncoder(RERANKER_NAME, device=device)
    loss_fct = nn.BCEWithLogitsLoss()

    # â­â­ í•™ìŠµ ì „ì— ì¶œë ¥ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³  ìƒì„± â­â­
    output_path_obj = Path(OUTPUT_MODEL_PATH)
    try:
        output_path_obj.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± ë˜ëŠ” í™•ì¸ ì™„ë£Œ: {OUTPUT_MODEL_PATH}")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨. ê¶Œí•œ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤: {e}")
        return  # ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨ ì‹œ í•¨ìˆ˜ ì¢…ë£Œ

    # 4. ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
    print(f"ğŸš€ íŒŒì¸íŠœë‹ ì‹œì‘: {NUM_EPOCHS} ì—í¬í¬")
    model.fit(
        train_dataloader=train_dataloader,
        loss_fct=loss_fct,
        epochs=NUM_EPOCHS,
        warmup_steps=100,
        output_path=OUTPUT_MODEL_PATH,
        optimizer_params={'lr': LEARNING_RATE},
        show_progress_bar=True
    )

    # âœ… í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ ìˆ˜ë™ ì €ì¥ (í•„ìˆ˜)
    model.save(OUTPUT_MODEL_PATH)

    # ì €ì¥ëœ ëª¨ë¸ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê³„ì‚°í•˜ì—¬ ì¶œë ¥
    absolute_path = output_path_obj.resolve()

    print(f"\nâœ… íŒŒì¸íŠœë‹ ì™„ë£Œ. ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ê²½ë¡œ (ì ˆëŒ€ ê²½ë¡œ): {absolute_path}")


if __name__ == '__main__':
    fine_tune_reranker()