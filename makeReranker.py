# reranker_finetuner.py
import json
from pathlib import Path
import torch
from torch import nn  # nn ëª¨ë“ˆ ì¶”ê°€
from torch.utils.data import DataLoader
from sentence_transformers import CrossEncoder, InputExample, losses

# 1. ì„¤ì •
RERANKER_NAME = 'cross-encoder/ms-marco-TinyBERT-L-2'
HIL_DATA_DIR = Path("./hil_training_data")
OUTPUT_MODEL_PATH = './custom_finetuned_reranker'

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
BATCH_SIZE = 16
NUM_EPOCHS = 3
LEARNING_RATE = 2e-5

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ì„¤ì •
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"Using device: {device}")


# 2. ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„
def load_and_prepare_data(data_dir: Path):
    """ì €ì¥ëœ JSON íŠ¸ë¦½ë › ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  InputExample ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    train_examples = []

    for json_file in data_dir.glob("triplet_*.json"):
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        query = data['query']
        pos_content = data['positive']['content']

        # ê¸ì • ìŒ (Positive Pair) ì¶”ê°€: ë ˆì´ë¸” 1.0 (ë§¤ìš° ê´€ë ¨ ìˆìŒ)
        train_examples.append(InputExample(texts=[query, pos_content], label=1.0))

        # ë¶€ì • ìŒ (Negative Pairs) ì¶”ê°€: ë ˆì´ë¸” 0.0 (ê´€ë ¨ ì—†ìŒ)
        for neg in data['negatives']:
            neg_content = neg['content']
            train_examples.append(InputExample(texts=[query, neg_content], label=0.0))

    print(f"ğŸ’¾ ì´ {len(train_examples)}ê°œì˜ í•™ìŠµ ìŒì„ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.")
    return train_examples


# 3. ëª¨ë¸ íŒŒì¸íŠœë‹ í•¨ìˆ˜
def fine_tune_reranker():
    # ë°ì´í„° ë¡œë“œ
    train_examples = load_and_prepare_data(HIL_DATA_DIR)
    if not train_examples:
        print("í•™ìŠµ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ íŒŒì¸íŠœë‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=BATCH_SIZE)

    # ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš© ì„¤ì •)
    model = CrossEncoder(RERANKER_NAME, device=device)

    # 3. ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •: CrossEncoderì˜ í‘œì¤€ ì†ì‹¤ í•¨ìˆ˜ (Binary Classification)
    # CrossEncoderëŠ” 0ê³¼ 1 ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ë¯€ë¡œ BCEWithLogitsLossê°€ ì í•©í•©ë‹ˆë‹¤.
    loss_fct = nn.BCEWithLogitsLoss()

    # 4. ëª¨ë¸ í•™ìŠµ ì‹¤í–‰ (TypeError í•´ê²°)
    print(f"ğŸš€ íŒŒì¸íŠœë‹ ì‹œì‘: {NUM_EPOCHS} ì—í¬í¬")
    model.fit(
        # ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„: train_objectives ëŒ€ì‹  train_dataloaderì™€ loss_fctë¥¼ ì‚¬ìš©
        train_dataloader=train_dataloader,
        loss_fct=loss_fct,
        epochs=NUM_EPOCHS,
        warmup_steps=100,
        output_path=OUTPUT_MODEL_PATH,
        optimizer_params={'lr': LEARNING_RATE},
        show_progress_bar=True
    )

    print(f"\nâœ… íŒŒì¸íŠœë‹ ì™„ë£Œ. ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {OUTPUT_MODEL_PATH}")


if __name__ == '__main__':
    fine_tune_reranker()