# chatbot_fixed_v3.py
import re
from typing import List
from commonUtil.timeCheck import logging_time
# ---------- ì „ì—­ ì„¤ì • (í† í° ê¸°ë°˜ ë¶„í•  ê¸°ì¤€) ----------
DB_FOLDER = "./chroma_db3" #-- ê¸°ë³¸ì€ ./chroma_db2
# ----------------------------------------------------

# --- Imports: try newest, fallback to older packages if necessary ---
try:
    from langchain_chroma import Chroma
except Exception:
    from langchain_community.vectorstores import Chroma  # older langchain versions

try:
    from langchain_ollama import OllamaLLM
except Exception:
    from langchain_community.llms import Ollama as OllamaLLM  # fallback (older)

# Embeddings import fallback handling
try:
    from langchain_huggingface import HuggingFaceEmbeddings
except Exception:
    try:
        from langchain_community.embeddings import HuggingFaceEmbeddings
    except Exception:
        raise ImportError("HuggingFaceEmbeddings import failed. Install langchain_huggingface or langchain-community.")

from langchain.prompts import PromptTemplate
from langchain.chains import RetrievalQA
from langchain.schema import Document

# ---------- PROMPT ----------
PROMPT_TEMPLATE = """ë‹¹ì‹ ì€ íšŒì‚¬ ê²Œì‹œíŒì˜ ë¬¸ì„œë“¤ì„ ë¶„ì„í•˜ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì˜ ì‹¤ì œ ë‚´ìš©ì…ë‹ˆë‹¤:
{context}

[ì§€ì‹œì‚¬í•­]
1. ë°˜ë“œì‹œ ë¬¸ì„œ ë‚´ìš©ì—ë§Œ ê·¼ê±°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
2. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , "ê´€ë ¨ ë¬¸ì„œì—ì„œ í•´ë‹¹ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”.
3. ì—¬ëŸ¬ ë¬¸ì„œê°€ ê²€ìƒ‰ëœ ê²½ìš°, metadataì˜ 'date' ê°’ì´ ê°€ì¥ ìµœì‹ ì¸ ë¬¸ì„œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
4. ë‚ ì§œê°€ ë™ì¼í•œ ê²½ìš° metadataì˜ 'ê²Œì‹œì¼ì‹œ'ë¥¼ ë¹„êµí•´ ìµœì‹  ê²Œì‹œê¸€ì„ ì„ íƒí•˜ì„¸ìš”.
5. ê°€ëŠ¥í•œ ê²½ìš° ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”: ì œëª©, ê²Œì‹œì, ê²Œì‹œì¼ì.

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}
"""

# ---------- ë²¡í„° DB ë¡œë“œ ----------
def load_vector_db(persist_dir: str = DB_FOLDER):
    embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")
    db = Chroma(persist_directory=persist_dir, embedding_function=embeddings)
    return db

# ---------- LLM ë¡œë“œ ----------
def load_llm():
    # temperature ë‚®ê²Œ í•´ì„œ ì¶”ì¸¡ ì¤„ì„
    try:
        return OllamaLLM(model="llama3.1:8b", temperature=0.0)
    except TypeError:
        # ì¼ë¶€ ë˜í¼ëŠ” í‚¤ì›Œë“œëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ positional fallback
        return OllamaLLM("llama3.1:8b")

# ---------- QA ì²´ì¸ ìƒì„± ----------
def create_qa_chain():
    db = load_vector_db()
    retriever = db.as_retriever(search_kwargs={"k": 10})
    llm = load_llm()

    # map_prompt / combine_prompt ì„ PromptTemplate ìœ¼ë¡œ ëª…ì‹œ
    map_prompt = PromptTemplate(
        input_variables=["context", "question"],
        template=PROMPT_TEMPLATE
    )
    combine_prompt = PromptTemplate(
        input_variables=["summaries", "question"],
        template=(
            "ì•„ë˜ëŠ” ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ ì¶”ì¶œí•œ ìš”ì•½ì…ë‹ˆë‹¤:\n\n{summaries}\n\n"
            "ìœ„ ìš”ì•½ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë¬¸ì„œ ê·¼ê±°ë§Œ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”. "
            "ë¬¸ì„œì— ì—†ìœ¼ë©´ 'ê´€ë ¨ ë¬¸ì„œì—ì„œ í•´ë‹¹ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µí•˜ì„¸ìš”.\n\n"
            "ì‚¬ìš©ì ì§ˆë¬¸: {question}\n"
        )
    )

    # RetrievalQA.from_chain_type ì—ì„œ map_prompt / combine_prompt ì „ë‹¬
    try:
        qa = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=retriever,
            chain_type="stuff",  # map_reduce ëŒ€ì‹  stuff ì‚¬ìš©
        )
    except TypeError:
        # ì¼ë¶€ LangChain ë²„ì „ì—ì„œ key ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê¸°ë³¸ stuff ë¡œ fallback
        qa = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=retriever,
            chain_type="stuff"
        )

    return qa, retriever

# ---------- ì œëª© ê¸°ë°˜ í•„í„° ----------
def filter_by_title(query: str, docs: List[Document]) -> List[Document]:
    title_pattern = re.search(r"ì œëª©.*?(?:ì´|ì—)?\s*([^\s]+)", query)
    if not title_pattern:
        return docs
    keyword = title_pattern.group(1).strip()
    filtered = [d for d in docs if keyword in (d.metadata.get("title") or "")]
    return filtered if filtered else docs

# ---------- ë‹µë³€ ìƒì„± ----------
@logging_time
def get_answer(qa, query: str):
    # RetrievalQA ë‚´ë¶€ì—ì„œ retrieverë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ê·¸ëƒ¥ invoke
    try:
        result = qa.invoke({"query": query})
        # result may be a dict or string depending on version
        if isinstance(result, dict):
            return result.get("result") or result.get("answer") or str(result)
        return str(result)
    except Exception:
        # some versions expect run or call
        try:
            return qa.run(query)
        except Exception as e:
            return f"LLM ì²´ì¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}"

# ---------- ë©”ì¸ ----------
def main():
    print("ğŸ¤– ê²Œì‹œíŒ ê¸°ë°˜ ì±—ë´‡ (Ctrl+C ë¡œ ì¢…ë£Œ)\n")
    qa, retriever = create_qa_chain()

    while True:
        try:
            query = input("ğŸ—¨ï¸ ì§ˆë¬¸: ").strip()
            if not query:
                continue

            docs = retriever.get_relevant_documents(query)
            docs = filter_by_title(query, docs)

            # ë””ë²„ê¹…ìš©: ê²€ìƒ‰ëœ context ê°„ë‹¨ ì¶œë ¥
            print("\nğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ(ìš”ì•½):")
            for i, d in enumerate(docs, 1):
                title = d.metadata.get("title", "ì œëª© ì—†ìŒ")
                date = d.metadata.get("date", "ë‚ ì§œ ì—†ìŒ")
                source = d.metadata.get("source", "ì¶œì²˜ ì—†ìŒ")
                snippet = d.page_content[:200].replace("\n", " ")
                print(f"  [{i}] {title} / {date} / {source}\n       {snippet}...\n")

            response = get_answer(qa, query)
            print("\nğŸ’¬ ë‹µë³€:\n", response)

            print("\nğŸ“š ì°¸ê³  ë¬¸ì„œ ëª©ë¡:")
            for i, d in enumerate(docs, 1):
                print(f"  [{i}] ì¶œì²˜: {d.metadata.get('source','ì•Œ ìˆ˜ ì—†ìŒ')} / ë‚ ì§œ: {d.metadata.get('date','ì•Œ ìˆ˜ ì—†ìŒ')}")

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

if __name__ == "__main__":
    main()
